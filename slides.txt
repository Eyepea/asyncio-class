= Using asyncio in Python 3.4
:author:    Aaron Maxwell <amax@redsymbol.net>, Ludovic Gasc (GMLudo)
:backend:   slidy
:max-width: 45em
:source-highlighter: pygments
:data-uri:
:icons:

== Preface

*+git clone https://git@github.com/Eyepea/asyncio-class.git+*

To fully participate: make sure you have Python 3.4 installed on your
machine, and are able to start up the Python interpreter. (Earlier
versions aren't compatible with this c
ourse.) If you don't, get it
from https://www.python.org/downloads/ now, while we're waiting to get started.

**Tip**: On Linux, you can use pythonz, to install quickly Python 3.4: http://saghul.github.io/pythonz/

== Concepts

asyncio is a module implementing asynchronous I/O, built into Python
3. Some of its key concepts:

* event loops
* coroutines
* transports
* protocols

Technical details: http://python.org/dev/peps/pep-3156/

Implementation: https://hg.python.org/cpython/file/40c031308967/Lib/asyncio

== Back to basics: "yield" (1)

"yield" is a keyword that is used like return, except the function will return a generator.

Generators are iterators (ex: a list), but you can only iterate over them once. It's because they do not store all the values in memory, they generate the values on the fly.

Example:

[source,python]
----
def yield_example():
     print('start')
     yield
     print('continue')
     yield
     print('stop')

generator = yield_example()
next(generator)
----

== Back to basics: "yield" (2)

Yield example with a return value:

[source,python]
----
def return_yield_example():
     for i in range(5):
         yield i*i

for j in return_yield_example():
     print(j)
----

== asyncio uses "yield from"

Python 3.4 introduced the "yield from" expression. It looks similar
to, but behaves different from, a simple "yield".

Learn about this in PEP 380: http://legacy.python.org/dev/peps/pep-0380/

== Source code of "yield from"

[source,python]
----
RESULT = yield from EXPR
----

=

[source,python]
----
_i = iter(EXPR)
try:
    _y = next(_i)
except StopIteration as _e:
    _r = _e.value
else:
    while 1:
        try:
            _s = yield _y
        except GeneratorExit as _e:
            try:
                _m = _i.close
            except AttributeError:
                pass
            else:
                _m()
            raise _e
        except BaseException as _e:
            _x = sys.exc_info()
            try:
                _m = _i.throw
            except AttributeError:
                raise _e
            else:
                try:
                    _y = _m(*_x)
                except StopIteration as _e:
                    _r = _e.value
                    break
        else:
            try:
                if _s is None:
                    _y = next(_i)
                else:
                    _y = _i.send(_s)
            except StopIteration as _e:
                _r = _e.value
                break
RESULT = _r
----

== In a generator / coroutine code

[source,python]
----
return value
----

=

[source,python]
----
raise StopIteration(value)
----

== AsyncIO Debug

* launch: export PYTHONASYNCIODEBUG=1
* The asyncio module logs information with the logging module in the logger 'asyncio'.

Details on: https://docs.python.org/3/library/asyncio-dev.html

== Event Loops

* Built-in construct managing event waiting and dispatch
* Normally you can just use the default loop
* Can be configured, modified, refined, etc. when you do

[source,python]
----
# Most of the time, you'll just start your '__main__' function
# with something like this.
import asyncio
loop = asyncio.get_event_loop()
----

== Coroutines

In Python asyncio, a coroutine is a generator that follows certain
conventions.

A generator is a coroutine if it: 

 * returns a value (to the calling coroutine)
 * yields from a future 
 * yields from another coroutine

Note that it doesn't just yield (i.e. it's "yield from <something>",
not "yield <value>".

See "The difference between yield and yield-from" by Guido:

https://groups.google.com/forum/#!topic/python-tulip/bmphRrryuFk

== More Coroutine Fun Facts

* Coroutines can only run when the event loop is running
* Coroutines don't start running automatically.
* You schedule coroutines to run by:
  - yielding from it (in another calling coroutine)
  - create a task, then schedule it
  - or use loop.async(coro())(< Python 3.4.2) or loop.create_task(coro()) (>= Python 3.4.2) do both in one step

== Coroutines 

Coroutines are technically optional in asyncio. But you should use
them, as a lot of asyncio's functionality and expressive power becomes
much much easily accessible.

The trade-off is that you must learn to think in new ways; coroutines
and 3.4's "yield from" construct are rare in mainstream programming
languages, so you likely haven't worked with anything like them
before.

Further self-education: 

* PEP 342 - "Coroutines via Enhanced Generators" (how Python
  coroutines extend Python generators) 
* PEP 380 - "Syntax for Delegating to a Subgenerator" (the "yield  from" PEP)

== Futures in asyncio

* A Future represents a computation in progress - the asynchronous
execution of a callable.
* asyncio.Future is _almost_ compatible with
concurrent.futures.Future
* you can yield from a future!

Important methods:

* done() - True iff the future has a result
* set_result() - Complete the future with a given result
* result() - Return the result, or raise an exception if none set yet.
* cancel() - Cancel the future.

== Future exercise

Open a Python 3 terminal, and type the following:

[source,python]
----
import asyncio
future = asyncio.Future()
----

Play with invoking the following methods on the future object:

 * done()
 * result()
 * set_result('Your Name')
 * cancelled()
 * cancel()

== Futures Eventually Have A Result

[source,python]
----
>>> import asyncio
>>> future = asyncio.Future()
>>> future.done()
False
>>> # This raises an exception, because the future is not yet done.
... future.result()
Traceback (most recent call last):
  File "<stdin>", line 2, in <module>
  File "/home/amax/opt/Python-3.4.1/lib/python3.4/asyncio/futures.py", line 237, in result
    raise InvalidStateError('Result is not ready.')
asyncio.futures.InvalidStateError: Result is not ready.
>>> future.set_result('foo')
>>> future.done()
True
>>> future.result()
'foo'
----

== Tasks are a kind of Future
* A Task manages an independently running coroutine
* In fact, asyncio.Task subclasses asyncio.Future

== You start a coroutine running with a Task

In asyncio, when you define a coroutine - which, remember, is a
generator - it doesn't start executing right away. 

You run it by wrapping the coroutine in a task, and then running that
task in the event loop.

(This is the run_until_complete() method.)

[source,python]
----
import asyncio
# create a task object, and then...
loop = asyncio.get_event_loop()
loop.run_until_complete(task)
----

== Creating a task

Open a file named task_demo.py, and type in the following (you can
skip the comments).

[source,python]
----
import asyncio

@asyncio.coroutine
def my_coro():
    print('Hello, YOUR NAME')

# The factory function async() takes either a coroutine
# object or a future, and wraps it in a task.
task = asyncio.Task(my_coro())

# Note that I passed the coroutine *object*, not function.
# I.e. "my_coro()" not "my_coro"

loop = asyncio.get_event_loop()
loop.run_until_complete(task)
----

(What happens if you comment out the last line?)

== Transports

* Represents an I/O endpoint for network or local communication
* Think of it as a generalization of both a network socket and file
  handle, with useful methods
* can be bidirectional/streaming; unidirectional; datagram; or
  subprocess (piped I/O)

== Protocols

* Represents the application layer, i.e. _what_ bytes are sent over a
  transport
* Always used in conjunction with transports
* Can be streaming (bi-dir), datagram, or custom
* There are a few standard reusable protocol classes. Substantial
  software systems will implement their own

== Transports vs. Protocols

A transport is responsible for _how_ bytes are transmitted.

A protocol defines _what_ bytes to transmit, and when.

Asyncio separates these concerns, so they can be more easily
composed. This is uncommon but powerful.

== Implementing a Protocol

asyncio provides a base Protocol class, that you can use to implement
protocols for TCP servers.

You implement a protocol by subclassing asyncio.Protocol, and
overriding certain methods. The ones we will look at are:

 * connection_made(self, transport)
 * data_received(self, data)
 * connection_lost(self, exc)

== Let's Make an Echo Server

You will need:

 * telnet, or some variant of netcat (nc, ncat, etc.)
 * Python 3.4

Create a file named "echo_server_simple.py" and start it like this:
[source,python]
----
import asyncio
PORT = 4242
class SimpleEchoProtocol(asyncio.Protocol):
    pass
----

== Creating The Server

The event loop has a method called create_server we are going to
leverage. It handles creating and passing the transport to the
protocol methods for us.

Add the following lines to the end of echo_server_simple.py:

[source,python]
----
loop = asyncio.get_event_loop()
pending_server = loop.create_server(SimpleEchoProtocol, 'localhost', PORT)
server = loop.run_until_complete(pending_server)
loop.run_until_complete(server.wait_closed())
----

create_server() returns a coroutine. The server starts when this
coroutine is run by the event loop.

== Making the connection

The Protocol.connection_made method is invoked when a client makes an
incoming TCP connection. Its argument is a transport object, which in
this case represents a TCP socket connection. The code for
create_server conveniently provides for us.

[source,python]
----
import asyncio
PORT = 4242
class SimpleEchoProtocol(asyncio.Protocol):
    def connection_made(self, transport):
        print('Connection made')
        # We keep the transport object, so we can
        # write to it later.
        self.transport = transport
----

== Receiving Data

When inbound data is received on the socket, the protocol's
data_received method is invoked. Since this is an echo server, we want
to parrot what we receive right back.

Add the following method to SimpleEchoProtocol:

[source,python]
----
    # new method of SimpleEchoProtocol
    def data_received(self, data):
        print(data)
        # This is why we kept the transport when
        # making the connection.
        self.transport.write(b'echo:')
        self.transport.write(data)
----

== Closing the connection

When the connection is broken, the protocol object's connection_lost
method is invoked. If this is done cleanly, its argument is None; else
it is passed an exception object.

Add this method to SimpleEchoProtocol:
[source,python]
----
    # new method of SimpleEchoProtocol
    def connection_lost(self, exc):
        print("Connection lost! Closing server...")
        # This variable "server" will be in global scope by
	# the time the method is invoked.
        server.close()
----

== Test it out

[source,bash]
----
# In one terminal tab:
python3 echo_server_simple.py

# In another tab:
netcat localhost 4242

# Or you can use telnet, or nc, or ncat, or...
telnet localhost 4242
----

Type in a few characters and press <enter> at the telnet
prompt. Notice what it replies with. Look at the python3 process tab,
and note its output.

== Using Tasks

We just implemented a simple TCP server using asyncio's Protocol
abstraction. Another way to implement servers is by using Tasks.

Let's implement the echo server again, using the task approach.

Along the way, we will also learn about using callbacks in asyncio.

== Callbacks for futures and tasks

asyncio.Future has a method named add_done_callback. This lets you
register a callable, that is invoked when the future is done.

(Remember, a task is a future too - one that runs a coroutine.)

The callback is passed the task object as an argument.

== Task callback example

Type the following into a file named run_task.py:

[source,python]
----
import asyncio
task = asyncio.Task(asyncio.sleep(1))
def announce_task_done(task):
    print("Task is done: " + str(id(task)))
task.add_done_callback(announce_task_done)
asyncio.get_event_loop().run_until_complete(task)
----

Then invoke with "python3 run_task.py".

What happens if you omit the last line?

What happens if you _duplicate_ the last line, so it is run twice?

== Helper function: asyncio.start_server

start_server takes a callable argument (along with a host and
port). The callable is a callback that handles a client connection.

Each new connection on the protocol re-invokes it.

[source,python]
----
import asyncio
def client_connected_handler(client_reader, client_writer):
    print('Got connection from client')

pending_server = asyncio.start_server(client_connected_handler,
                 'localhost', PORT)
----

== Simple Callback Server

Create a file named echo_server_task.py and type this in:

[source,python]
----
import asyncio
PORT = 4242
NUM_CLIENTS = 0
def client_connected_handler(client_reader, client_writer):
    print('Got connection from client')
loop = asyncio.get_event_loop()
pending_server = asyncio.start_server(client_connected_handler,
                 'localhost', PORT)
server = loop.run_until_complete(pending_server)
try:
    loop.run_forever()
except KeyboardInterrupt:
    print('\n{} Clients Served'.format(NUM_CLIENTS))
finally:
    loop.close()
----

Then run with python3, and connect with telnet or netcat as before.

== Echoing action

We want to add in actual echoing behavior. The echoing action is
handled by fetching data from the reader, and writing it right back to
the writer. Add this function to echo_server_task.py:

[source,python]
----
@asyncio.coroutine
def handle_client(client_reader, client_writer):
    print('New client')
    while not client_reader.at_eof():
        data = (yield from client_reader.readline())
        print(data)
        client_writer.write(b'echo:' + data)
----

The next step is to wire it up to the server, so it is applied to
incoming connections.

== Scheduling The Task

To make this connection, we will use a task. Modify client_connected_handler like so:

[source,python]
----

def client_done(future):
    global NUM_CLIENTS
    NUM_CLIENTS += 1
    print('Client done')

def client_connected_handler(client_reader, client_writer):
    task = asyncio.Task(handle_client(client_reader, client_writer))
    task.add_done_callback(client_done)
----

Then start your echo server again, and try to connect.

== aiohttp: Client

aiohttp is a library that implements HTTP protocol with AsyncIO.

Examples in: https://github.com/KeepSafe/aiohttp/tree/master/examples

In a coroutine, add this code:
[source,python]
----
#!/usr/bin/env python3

import aiohttp
import sys
import asyncio


def curl(url):
    response = yield from aiohttp.request('GET', url)
    print(repr(response))

    chunk = yield from response.content.read()
    print('Downloaded: %s' % len(chunk))

    response.close()


if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    loop.run_until_complete(curl(sys.argv[1]))
----

== aiohttp: Basic server

[source,python]
----
"""Basic http server with minimal setup"""
import aiohttp
import aiohttp.server

import asyncio
from urllib.parse import urlparse, parse_qsl
from aiohttp.multidict import MultiDict


class HttpRequestHandler(aiohttp.server.ServerHttpProtocol):

    @asyncio.coroutine
    def handle_request(self, message, payload):
        response = aiohttp.Response(
            self.writer, 200, http_version=message.version)
        content = "<h1>It Works!</h1>"
        bcontent = content.encode('utf-8')
        response.add_header('Content-Type', 'text/html; charset=UTF-8')
        response.add_header('Content-Length', str(len(bcontent)))
        response.send_headers()
        response.write(bcontent)
        yield from response.write_eof()


if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    f = loop.create_server(
        lambda: HttpRequestHandler(debug=True, keep_alive=75),
        '0.0.0.0', '8080')
    srv = loop.run_until_complete(f)
    print('serving on', srv.sockets[0].getsockname())
    try:
        loop.run_forever()
    except KeyboardInterrupt:
        pass
----

== aiohttp: Complete server

[source,python]
----
"""Basic http server with minimal setup"""
import aiohttp
import aiohttp.server

import asyncio
from urllib.parse import urlparse, parse_qsl
from aiohttp.multidict import MultiDict


class HttpRequestHandler(aiohttp.server.ServerHttpProtocol):

    @asyncio.coroutine
    def handle_request(self, message, payload):
        response = aiohttp.Response(
            self.writer, 200, http_version=message.version)
        get_params = MultiDict(parse_qsl(urlparse(message.path).query))
        if message.method == 'POST':
            post_params = yield from payload.read()
        else:
            post_params = None
        content = "<h1>It Works!</h1>"
        if get_params:
            content += "<h2>Get params</h2><p>" + str(get_params) + "</p>"
        if post_params:
            content += "<h2>Post params</h2><p>" + str(post_params) + "</p>"
        bcontent = content.encode('utf-8')
        response.add_header('Content-Type', 'text/html; charset=UTF-8')
        response.add_header('Content-Length', str(len(bcontent)))
        response.send_headers()
        response.write(bcontent)
        yield from response.write_eof()


if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    f = loop.create_server(
        lambda: HttpRequestHandler(debug=True, keep_alive=75),
        '0.0.0.0', '8080')
    srv = loop.run_until_complete(f)
    print('serving on', srv.sockets[0].getsockname())
    try:
        loop.run_forever()
    except KeyboardInterrupt:
        pass
----

== aiohttp: multi-process server

https://github.com/KeepSafe/aiohttp/blob/master/examples/mpsrv.py

== aiorest: example

[source,python]
----
import asyncio
import aiohttp
import aiorest


# define a simple request handler
# which accept no arguments
# and responds with json
def hello(request):
    return {'hello': 'world'}


loop = asyncio.get_event_loop()
server = aiorest.RESTServer(hostname='127.0.0.1',
                            loop=loop)

# configure routes
server.add_url('GET', '/', hello)
# create server
srv = loop.run_until_complete(loop.create_server(
    server.make_handler, '127.0.0.1', 8080))

loop.run_forever()
----

== Benchmarks with wrk

Modern HTTP benchmarking tool: https://github.com/wg/wrk

Example:

[source,python]
---
wrk -t12 -c400 -d30s http://127.0.0.1:8080/index.html
---

== Thank you!

For being beta testers for this free class in asyncio.

Contact us any time:

=== Author

 - Aaron Maxwell
 - amax@redsymbol.net
 - http://linkedin.com/in/aaronmaxwell
 - "redsymbol" on github, hacker news, twitter, etc.

=== Contributors

 - Ludovic Gasc (GMLudo)
 - https://twitter.com/GMLudo
 - https://github.com/GMLudo

////////////////
== Why Separate them?

Most networking libraries don't explicity have separate abstractions
for transports and protocols. Even the standard library often doesn't
separate them, internally; the code for each is mixed together.

However, it is a powerful generalization that lets us use the same
protocols over different, even new transports (e.g. RPC), and even
nest protocols (e.g. JSON-RPC).

The ideas of transport and protocol are fleshed out more in PEP 3153,
"Asynchronous IO support"

== More Advanced Background

These are things that don't necessarily have anything to do with
Python, but are worth your time if you want to master the full range
of what asyncio makes possible.

* "Multi-core scaling: it’s not multi-threaded" by Robert Graham - http://blog.erratasec.com/2013/02/multi-core-scaling-its-not-multi.html
* "Linux System Programming (2nd Ed.), by Robert Love (pub. O'Reilly) - My *FAVORITE*
software book of 2013 (and 2014, so far). Has a great chapter on
threads programming, though to get the most out of it you'll want to
read most of the rest of the book too.

TODO: Tasks

[source,python]
----
def foo(x):
    print(x)
foo("Hello World")
----

"The difference between yield and yield-from" by Guido:
https://groups.google.com/forum/#!topic/python-tulip/bmphRrryuFk
(It also explains why coroutines in asyncio use just yield from, and
not yield.)

== Resources

asyncio (formerly named "tulip"):

* http://python.org/dev/peps/pep-3156/
* http://docs.python.org/3.4/library/asyncio.html

Coroutines:

* http://python.org/dev/peps/pep-0342/
* http://www.dabeaz.com/coroutines/

Misc:

* Great article by Glyph putting asyncio in larger context - https://glyph.twistedmatrix.com/2014/02/unyielding.html
* Excellent gentle tutorial - http://www.getoffmalawn.com/blog/playing-with-asyncio
* "yield from" PEP - http://python.org/dev/peps/pep-0380/


== Example
[source,python]
----
# This is a coroutine.
import asyncio
@asyncio.coroutine
def transfer_data(src_reader, dest_writer):
    # Handle the requests for a specific client with a line oriented protocol
    while True:
        # Read a line
        data = (yield from src_reader.readline())
        # Send it to the destination
        dest_writer.write(data)
----

== Coroutines

* In Python, a coroutine is a generator
* In asyncio, a generator that follows certain conventions
* In particular, produces values via "return" or "yield from" (or
throwing an exception)
* Does NOT use "yield"


////////////////

